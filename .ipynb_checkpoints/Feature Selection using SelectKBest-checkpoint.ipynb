{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "**Programmer:** python_scripts (Abhijith Warrier)\n",
    "\n",
    "**PYTHON SCRIPT TO **_SELECT TOP-k FEATURES WITH `SelectKBest` AND BUILD A CLEAN CLASSIFICATION PIPELINE._** üêçüß™üìä**\n",
    "\n",
    "This script shows how to use **univariate feature selection** with the **ANOVA F-test** (`f_classif`) to keep the most informative features, avoid overfitting, and simplify your model. We‚Äôll fit a pipeline: **SelectKBest ‚Üí LogisticRegression**, evaluate performance, and inspect which features were kept."
   ],
   "id": "c8096230fd255995"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üì¶ Import Libraries\n",
    "We‚Äôll use scikit-learn for dataset, feature selection, modeling, and metrics. Matplotlib/Pandas for reporting."
   ],
   "id": "a281b90ac00efdbf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "id": "6a098f2bb78dff3d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üì• Load Tabular Dataset\n",
    "Using the **Breast Cancer Wisconsin** dataset (binary classification).\n",
    "We‚Äôll keep feature names for easy interpretation later."
   ],
   "id": "3775bfbfc21f7bf2"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "data = load_breast_cancer()\n",
    "X, y = data.data, data.target\n",
    "feature_names = np.array(data.feature_names)  # numpy array for easy indexing\n",
    "\n",
    "print(f\"X shape: {X.shape} | y shape: {y.shape}\")\n",
    "print(\"Classes:\", list(data.target_names))"
   ],
   "id": "ed48f07e92abe999"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ‚úÇÔ∏è Train/Test Split (Stratified)\n",
    "Hold out a test set; stratification preserves class balance."
   ],
   "id": "7955146b70fa1ebe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, stratify=y, random_state=42\n",
    ")"
   ],
   "id": "f29ec78a802a9729"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîé Configure `SelectKBest` (ANOVA F-test)\n",
    "- `f_classif` performs a univariate ANOVA F-test **per feature** for classification.\n",
    "- We‚Äôll select the **top k** features (set `k=10` as a starting point).\n",
    "> Best practice: put selection **inside a Pipeline** so it‚Äôs fit **only on training data** (no leakage)."
   ],
   "id": "c284115b31cba78a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "k = 10  # choose how many features to keep\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"scaler\", StandardScaler()),  # scale numeric features (helps LR)\n",
    "    (\"select\", SelectKBest(score_func=f_classif, k=k)),  # select top-k by ANOVA F\n",
    "    (\"clf\", LogisticRegression(max_iter=200, random_state=42))\n",
    "])"
   ],
   "id": "8d44c0ba3fefa1de"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üöÄ Train the Pipeline\n",
    "`fit()` will: scale ‚Üí score & select top-k (on train only) ‚Üí fit classifier."
   ],
   "id": "b8e70f7a2432abeb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "pipe.fit(X_train, y_train)",
   "id": "b4b4b34c7ed2ebb1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîÆ Evaluate on Test Set\n",
    "Use the same pipeline to transform test data and predict with the trained model."
   ],
   "id": "ef52aaf3f79e0149"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_pred = pipe.predict(X_test)\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {acc:.4f}\\n\")\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred, target_names=data.target_names))"
   ],
   "id": "7005755d8e32a22e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üßæ Inspect Selected Features & Scores\n",
    "Pull the **F-scores** from the fitted selector and see which features were kept."
   ],
   "id": "7a5ee5ed632e74d4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Access the fitted SelectKBest step\n",
    "selector = pipe.named_steps[\"select\"]\n",
    "\n",
    "# Boolean mask of selected features in ORIGINAL order\n",
    "mask = selector.get_support()\n",
    "\n",
    "# Scores for all features (align with feature_names)\n",
    "scores = selector.scores_\n",
    "\n",
    "# Build a table of (feature, score, selected) and sort by score\n",
    "report_df = pd.DataFrame({\n",
    "    \"feature\": feature_names,\n",
    "    \"f_score\": scores,\n",
    "    \"selected\": mask\n",
    "}).sort_values(\"f_score\", ascending=False)\n",
    "\n",
    "print(\"Top features by ANOVA F-score:\")\n",
    "report_df.head(15)"
   ],
   "id": "5fcdcd9d82450c1d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üìä Visualize Top-k Feature Scores\n",
    "Bar chart of the **k** best features chosen by `SelectKBest`."
   ],
   "id": "54f44af453a3a28b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "topk_df = report_df[report_df[\"selected\"]].copy()\n",
    "plt.figure(figsize=(9, 5))\n",
    "plt.barh(topk_df[\"feature\"], topk_df[\"f_score\"])\n",
    "plt.gca().invert_yaxis()\n",
    "plt.xlabel(\"ANOVA F-score\")\n",
    "plt.title(f\"Top {k} Features Selected by SelectKBest (f_classif)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "512326faab6ca952"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üìù Notes & Tips\n",
    "- **Choosing k:** Try several values (e.g., 5, 10, 15) and compare CV/test scores.\n",
    "- **Scoring function:** For classification, `f_classif` is common; for regression, use `f_regression`.\n",
    "- **Pipelines prevent leakage:** Selection is learned on **train only**, then applied to test.\n",
    "- **Alternatives:** `SelectPercentile`, `mutual_info_classif`, model-based selection (`SelectFromModel` with L1 or trees).\n",
    "- **Caveat:** Univariate tests ignore feature interactions; consider wrapper/embedded methods if interactions matter."
   ],
   "id": "9c3999febed1b711"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "98da5a2be5e20967"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
