{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": [
    "**Programmer:** python_scripts (Abhijith Warrier)\n",
    "\n",
    "**PYTHON SCRIPT TO **_FIT A POLYNOMIAL REGRESSION MODEL USING `PolynomialFeatures` + `LinearRegression` IN A PIPELINE._** üêçüß™üìà**\n",
    "\n",
    "This script generates a synthetic non-linear dataset, builds a **Pipeline (PolynomialFeatures ‚Üí LinearRegression)**, evaluates metrics (MAE/MSE/R¬≤), and visualizes the fitted curve vs. the data."
   ],
   "id": "402415ef15586dc7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üì¶ Import Libraries\n",
    "We‚Äôll use NumPy for data generation, scikit-learn for modeling/metrics, and matplotlib for visualization."
   ],
   "id": "6916436e2b280528"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ],
   "id": "904701ffba4bad64"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üß™ Create a Synthetic Non-Linear Dataset\n",
    "We‚Äôll simulate data from a quadratic relationship with noise:\n",
    "\\[\n",
    "y = 0.5x^2 - 2x + 3 + \\epsilon\n",
    "\\]"
   ],
   "id": "16816b388337b901"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "rng = np.random.RandomState(42)\n",
    "\n",
    "# Feature (single input) and target\n",
    "X = np.linspace(-5, 5, 120).reshape(-1, 1)\n",
    "true_y = 0.5 * X ** 2 - 2 * X + 3\n",
    "y = (true_y + rng.normal(scale=2.0, size=X.shape)).ravel()  # add Gaussian noise\n",
    "\n",
    "# Quick visual check of raw data\n",
    "plt.figure(figsize=(6.5, 4.5))\n",
    "plt.scatter(X, y, s=18, alpha=0.7, label=\"Noisy observations\")\n",
    "plt.plot(X, true_y, lw=2, label=\"True function\", color=\"orange\")\n",
    "plt.title(\"Synthetic Non-Linear Data\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "fe415dbe225370e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ‚úÇÔ∏è Train/Test Split\n",
    "Keep a hold-out set to estimate generalization performance."
   ],
   "id": "8ded113eed1184a3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=42\n",
    ")"
   ],
   "id": "f9e306002e2e5a9c"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### ‚öôÔ∏è Build the Polynomial Regression Pipeline\n",
    "Use `PolynomialFeatures(degree=d)` to expand inputs, then fit a linear model on the expanded features."
   ],
   "id": "16125d751644f951"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "degree = 2  # try 2 for quadratic; experiment with 3 or 4 as well\n",
    "\n",
    "poly_reg = Pipeline(steps=[\n",
    "    (\"poly\", PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "    (\"linreg\", LinearRegression())\n",
    "])"
   ],
   "id": "d680bc748e8a1511"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üöÄ Train the Model\n",
    "Fit the pipeline on the training set; it will expand features then fit Linear Regression."
   ],
   "id": "7d071311b2b4956a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "poly_reg.fit(X_train, y_train)",
   "id": "f6dc3b416613956a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üîé Evaluate on Test Set (MAE, MSE, R¬≤)\n",
    "Compute standard regression metrics to assess fit quality."
   ],
   "id": "71d26ef0289fe2c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "y_pred = poly_reg.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Degree: {degree}\")\n",
    "print(f\"MAE: {mae:.3f}\")\n",
    "print(f\"MSE: {mse:.3f}\")\n",
    "print(f\"R¬≤ : {r2:.3f}\")"
   ],
   "id": "bf2427dcb378372a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üìà Visualize the Fitted Curve\n",
    "Sort X across the full range, predict smoothly, and overlay with the noisy scatter."
   ],
   "id": "ab9ba0a71277f317"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Sort for a smooth fitted curve\n",
    "X_plot = np.linspace(X.min(), X.max(), 400).reshape(-1, 1)\n",
    "y_fit = poly_reg.predict(X_plot)\n",
    "\n",
    "plt.figure(figsize=(6.8, 4.8))\n",
    "plt.scatter(X_train, y_train, s=18, alpha=0.6, label=\"Train\")\n",
    "plt.scatter(X_test, y_test, s=18, alpha=0.8, label=\"Test\")\n",
    "plt.plot(X_plot, y_fit, lw=2.5, color=\"crimson\", label=f\"Polynomial fit (degree={degree})\")\n",
    "plt.plot(X, true_y, lw=2, color=\"orange\", alpha=0.8, label=\"True function\")\n",
    "plt.title(\"Polynomial Regression Fit\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "83a7df49f8d16b86"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### üìù Notes & Tips\n",
    "- **Bias‚ÄìVariance tradeoff:** Higher degree can reduce bias but may **overfit** (watch test R¬≤).\n",
    "- Try degrees **1‚Äì5** and pick the best via **cross-validation** (`GridSearchCV` over `poly__degree`).\n",
    "- For multi-feature data, polynomial expansion grows quickly; consider `degree` and **regularization** (`Ridge`, `Lasso`).\n",
    "- Keep `include_bias=False` since `LinearRegression` has an intercept by default."
   ],
   "id": "155af8fcda8c0be7"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "",
   "id": "d333b54b7283df1c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
