{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c38ef9165d46483",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "### **Programmer: python_scripts (Abhijith Warrier)**\n",
    "\n",
    "**PYTHON SCRIPT TO *DEPLOY A FASTAPI-BASED MACHINE LEARNING API TO RENDER OR RAILWAY*. üß†üåç‚ö°**\n",
    "\n",
    "This script demonstrates how to deploy an existing **FastAPI ML inference app** to a cloud platform like **Render** or **Railway**, making your machine learning model accessible via a public URL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3b7c398dfb74e8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d696b9ecaa1bcb9",
   "metadata": {},
   "source": [
    "## **üì¶ Install Required Packages**\n",
    "\n",
    "**Ensure your FastAPI ML app runs locally before deploying to the cloud.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0f6472f7c58b72e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastapi uvicorn scikit-learn joblib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa281492f42839",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74292bea3f35e67",
   "metadata": {},
   "source": [
    "## **üß© FastAPI ML Inference Code**\n",
    "\n",
    "**This is the same inference API we‚Äôve been using ‚Äî no changes required for cloud deployment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd47cac2a13ec263",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "from pydantic import BaseModel\n",
    "import joblib\n",
    "import numpy as np\n",
    "\n",
    "model = joblib.load(\"iris_model.joblib\")\n",
    "\n",
    "app = FastAPI(title=\"Deployed ML API\")\n",
    "\n",
    "class InputData(BaseModel):\n",
    "    features: list\n",
    "\n",
    "@app.get(\"/\")\n",
    "def home():\n",
    "    return {\"message\": \"ML API is running\"}\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "def predict(data: InputData):\n",
    "    arr = np.array(data.features).reshape(1, -1)\n",
    "    pred = model.predict(arr).tolist()\n",
    "    return {\"prediction\": pred}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a23b3079af33a89",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7989f5f89f113b5f",
   "metadata": {},
   "source": [
    "## **üåê Prepare the App for Cloud Execution**\n",
    "\n",
    "**Cloud platforms expose the port automatically ‚Äî we just need a dynamic port binding.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1325862807f72ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# No code change required for Render / Railway\n",
    "# Uvicorn will be started by the platform using the PORT environment variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed995b97fe654fbe",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2c6721469061a5",
   "metadata": {},
   "source": [
    "## **üöÄ Deploying on Render**\n",
    "\n",
    "**Steps to deploy your ML API on Render:**\n",
    "\n",
    "1. Push your code (including iris_model.joblib) to GitHub\n",
    "2. Go to **render.com ‚Üí New ‚Üí Web Service**\n",
    "3. Connect your GitHub repository\n",
    "4. Set **Build Command**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda1adb57ed0c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install fastapi uvicorn scikit-learn joblib numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fcffca731aae61",
   "metadata": {},
   "source": [
    "5. Set **Start Command**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b01ee93d7578465",
   "metadata": {},
   "outputs": [],
   "source": [
    "uvicorn main:app --host 0.0.0.0 --port $PORT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db354cf3b3d26795",
   "metadata": {},
   "source": [
    "6. Click **Deploy**\n",
    "\n",
    "Render will build and deploy your ML API automatically."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b942541498946c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bc25da1bd815ad",
   "metadata": {},
   "source": [
    "## **üöÑ Deploying on Railway**\n",
    "\n",
    "**Steps to deploy your ML API on Railway:**\n",
    "\n",
    "1. Push your code to GitHub\n",
    "2. Go to **railway.app ‚Üí New Project ‚Üí Deploy from GitHub Repo**\n",
    "3. Select your repository\n",
    "4. Set **Start Command**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f0795c89747b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "uvicorn main:app --host 0.0.0.0 --port $PORT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f1a6db59150102",
   "metadata": {},
   "source": [
    "5. Railway automatically installs dependencies and deploys the app"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9debfad9f2e5358f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739358fbce561fe8",
   "metadata": {},
   "source": [
    "## **üåç Test the Deployed ML API**\n",
    "\n",
    "**Once deployed, use the public URL to test inference.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abecbff2f49b8064",
   "metadata": {},
   "outputs": [],
   "source": [
    "curl -X POST \"https://your-app-url/predict\" \\\n",
    "     -H \"Content-Type: application/json\" \\\n",
    "     -d '{\"features\":[5.8,2.7,5.1,1.9]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421db1baa3e5ff9b",
   "metadata": {},
   "source": [
    "A valid response confirms successful cloud deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2a63892093c83e",
   "metadata": {},
   "source": [
    "**Sample Output:**\n",
    "\n",
    "```jsx\n",
    "{\"prediction\":[2]}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4e2f7849eb81ba",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e91989cc6d2b0ca",
   "metadata": {},
   "source": [
    "## **üß™ Why This Deployment Step Matters**\n",
    "\n",
    "**This step enables:**\n",
    "\n",
    "- real-world access to your ML model\n",
    "- integration with frontend apps and services\n",
    "- scalability without managing servers\n",
    "- a true production-style ML workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3b2e9cc213d74c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356d564b01ea338",
   "metadata": {},
   "source": [
    "## **Key Takeaways**\n",
    "\n",
    "1. FastAPI ML apps can be deployed easily on Render or Railway.\n",
    "2. No code changes are required if the API already works locally.\n",
    "3. Cloud platforms manage ports and runtime automatically.\n",
    "4. Public URLs make ML models accessible anywhere.\n",
    "5. This step completes the transition from local ML to cloud ML."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcda03f17370989",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c3aae726191966",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
